# Literature review — Bots & AI on Wikipedia (starter)

## 1) Tsvetkova, M., García-Gavilanes, R., Floridi, L., & Yasseri, T. (2017).
**Title:** Even good bots fight: The case of Wikipedia.  
**Where:** PLOS ONE 12(2): e0171774.  
**Google Scholar:** https://scholar.google.com/citations?hl=en&user=A9TtpWwAAAAJ (Tsvetkova profile).  
**pdf:** [pdf](https://pmc.ncbi.nlm.nih.gov/articles/PMC5322977/).  
**Summary:** Analyzes bot interactions on Wikipedia (2001–2010), showing bots can undo each other and create complex dynamics — a cautionary case for scaling automated enforcement.

---

## 2) Zheng, L. (Nico), Albano, C. M., Vora, N. M., Mai, F., & Nickerson, J. V. (2019).
**Title:** The Roles Bots Play in Wikipedia.  
**Where:** Proceedings of the ACM on Human-Computer Interaction / CSCW.  
**Google Scholar:** https://scholar.google.com (search "The Roles Bots Play in Wikipedia Zheng 2019").  
**pdf:** [pdf](https://www.fengmai.net/download/manuscripts/Zhengetal2019-The%20Roles%20Bots%20Play%20in%20Wikipedia-CSCW.pdf).  
**Summary:** Categorizes bot tasks, documents close human-bot teams, and discusses how bots shape content production and maintenance.

---

## 3) Brooks, C., Eggert, S., & Peskoff, D. (2024).
**Title:** The Rise of AI-Generated Content in Wikipedia.  
**Where:** WIKINLP (EMNLP workshop) / arXiv.  
**Google Scholar:** https://scholar.google.com/citations?hl=en&user=K30IvtMAAAAJ (Creston Brooks).  
**pdf:** [pdf](https://arxiv.org/abs/2410.08044) (see arXiv/ACL workshop proceedings for PDF).  
**Summary:** Detects rising rates of AI-generated content in recent English Wikipedia articles and discusses quality and bias concerns.

---

## 4) Reeves, N., & Simperl, E. (2025).
**Title:** Machines in the Margins: A Systematic Review of Automated Content Generation for Wikipedia.  
**Where:** arXiv preprint / Under review.  
**Google Scholar:** https://scholar.google.com (search "Machines in the Margins Reeves Simperl 2025").  
**pdf:** [pdf](https://arxiv.org/abs/2509.22443).  
**Summary:** Systematic review of automated content generation methods for Wikipedia, analyzing techniques, models, source content, and evaluation methodologies. Highlights the need for comprehensive evaluation frameworks to assess effectiveness and bias in automated systems.

---

## 5) Ashkinaze, J., et al. (2024).
**Title:** Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms.  
**Where:** arXiv preprint / Under review.  
**Google Scholar:** https://scholar.google.com (search "Seeing Like an AI Ashkinaze 2024").  
**pdf:** [pdf](https://arxiv.org/abs/2407.04183).  
**Summary:** Evaluates large language models' ability to detect and correct biased Wikipedia edits according to the Neutral Point of View policy. Reveals challenges in aligning AI outputs with community norms and highlights systematic misapplications of neutrality standards.

---

## 6) Abdullah, M. A. A., et al. (2025).
**Title:** Detection of Biased Phrases in the Wiki Neutrality Corpus for Fairer Digital Content Management Using Artificial Intelligence.  
**Where:** MDPI Information 9(7): 190.  
**Google Scholar:** https://scholar.google.com (search "Detection of Biased Phrases Wiki Neutrality Corpus Abdullah 2025").  
**pdf:** [pdf](https://www.mdpi.com/2504-2289/9/7/190).  
**Summary:** Presents AI-based methods for detecting biased phrases in Wikipedia using the Wiki Neutrality Corpus. Demonstrates effectiveness of automated bias detection for enhancing digital content management and ensuring neutrality in knowledge platforms.

---

## 7) Schweitzer, S., Dobson, K. S. H., & Waytz, A. (2024).
**Title:** Political Bot Bias in the Perception of Online Discourse.  
**Where:** Journal of Experimental Psychology / Northwestern University.  
**Google Scholar:** https://scholar.google.com (search "Political Bot Bias Perception Schweitzer 2024").  
**pdf:** [pdf](https://www.scholars.northwestern.edu/en/publications/political-bot-bias-in-the-perception-of-online-discourse).  
**Summary:** Examines how political partisans perceive opposing viewpoints in online discourse, revealing a bias where individuals are more likely to attribute counter-ideological content to bots rather than humans. Highlights the role of political bias in content attribution and perception.

---

## Suggested additional reads (to add)
- Wikimedia bot policy and documentation (for how flags are assigned).
- MediaWiki API docs (RecentChanges / Revisions) — for implementation details.
